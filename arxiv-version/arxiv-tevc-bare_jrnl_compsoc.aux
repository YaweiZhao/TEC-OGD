\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Zhu:2015tr}
\citation{Hazan2007Adaptive}
\citation{Hall:2015ct}
\citation{ShalevShwartz:2012dz}
\citation{Garber:2018wf}
\citation{Bedi:2018te}
\citation{Song:2008:RAT}
\citation{Moon:2010}
\citation{Zinkevich:2003}
\citation{Mokhtari:2016jz}
\citation{Yang:2016ud}
\citation{Lei:2017:CUO}
\citation{Zinkevich:2003}
\citation{Mokhtari:2016jz}
\citation{Yang:2016ud}
\citation{Zhang:2016wl}
\citation{Mokhtari:2016jz}
\citation{Zhang:2016wl}
\citation{Mokhtari:2016jz}
\citation{Zhang:2016wl}
\citation{Zhang:2016wl}
\citation{Zhang:2016wl}
\citation{Tarantola:2004:IPT}
\citation{Zhang:2016wl}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\newlabel{eq:regret_dy}{{1}{2}{Introduction}{equation.1.1}{}}
\citation{ShalevShwartz:2012dz}
\citation{Hazan2016Introduction}
\citation{Duchi:2011}
\citation{Zinkevich:2003}
\citation{Hazan2016Introduction}
\citation{Hazan2016Introduction}
\citation{Mokhtari:2016jz}
\citation{Yang:2016ud}
\citation{Zhang:2016wl}
\citation{Zhu:2015tr}
\citation{Besbes:2015gb}
\citation{Chiang2012Online}
\citation{Jadbabaie:2015wg}
\citation{Joulani:2017un}
\citation{Joulani:2017un}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Our method OGD recovers the state-of-the-art regret with improved query complexity. \relax }}{3}{table.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table_dynamic_regret}{{1}{3}{Our method OGD recovers the state-of-the-art regret with improved query complexity. \relax }{table.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{3}{section.2}}
\newlabel{sect_related_work}{{2}{3}{Related work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Regrets of OGD in the static environment.}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Regrets of OGD in the dynamic environment.}{3}{subsection.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Preliminaries}{3}{section.3}}
\newlabel{sect_preliminary}{{3}{3}{Preliminaries}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Notations and assumptions}{3}{subsection.3.1}}
\citation{ShalevShwartz:2012dz}
\citation{Hazan2016Introduction}
\citation{Duchi:2011}
\citation{Zinkevich:2003}
\citation{Zhang:2016wl}
\citation{Zhang:2016wl}
\newlabel{definition_f_t_smooth}{{1}{4}{$\beta $ smoothness}{Definition.1}{}}
\newlabel{assumption_f_t_strongly_convex}{{1}{4}{$\alpha $ strong convexity}{Assumption.1}{}}
\newlabel{assumption_bounded_gradient}{{2}{4}{Boundedness of gradients}{Assumption.2}{}}
\newlabel{assumption_bounded_distance_x}{{3}{4}{Boundedness of the domain of $\x $}{Assumption.3}{}}
\newlabel{assumption_bounded_variation}{{4}{4}{Boundedness of variations in the dynamic environment}{Assumption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Algorithm}{4}{subsection.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}A new theoretical analysis framework}{4}{section.4}}
\newlabel{sect_theoretical_analysis}{{4}{4}{A new theoretical analysis framework}{section.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces OGD: Online Gradient Descent.\relax }}{5}{algorithm.1}}
\newlabel{algo_ogd}{{1}{5}{OGD: Online Gradient Descent.\relax }{algorithm.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces OMGD: Online Multiple Gradient Descent \cite  {Zhang:2016wl}. \relax }}{5}{algorithm.2}}
\newlabel{algo_omgd}{{2}{5}{OMGD: Online Multiple Gradient Descent \cite {Zhang:2016wl}. \relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}High-level thought}{5}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Meta framework}{5}{subsection.4.2}}
\newlabel{theorem_high_level_regret}{{1}{5}{}{Theorem.1}{}}
\citation{Mokhtari:2016jz}
\newlabel{theorem_recurrsive_bound}{{2}{6}{}{Theorem.2}{}}
\newlabel{lemma_linear_x}{{1}{6}{Appeared in Proposition $2$ in \cite {Mokhtari:2016jz}}{Lemma.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Improved regret and query complexity for strongly convex $f_t$}{6}{section.5}}
\newlabel{sect_dynamic_regret_strongly_convex}{{5}{6}{Improved regret and query complexity for strongly convex $f_t$}{section.5}{}}
\newlabel{theorem_s_sc_regret}{{3}{6}{}{Theorem.3}{}}
\citation{Zhang:2016wl}
\citation{Zhang:2016wl}
\citation{Mokhtari:2016jz}
\citation{Zhang:2016wl}
\newlabel{lemma_previous_result_sc_regret}{{2}{7}{Appeared in Theorem $3$ and Corollary $4$ in \cite {Zhang:2016wl}}{Lemma.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{7}{section.6}}
\newlabel{sect_conclude}{{6}{7}{Conclusion}{section.6}{}}
\newlabel{equa_meta_dynamic_regret}{{2}{8}{Proof of theorems}{equation.Alph0.2}{}}
\newlabel{equa_upper_bound_I1}{{3}{8}{Proof of theorems}{equation.Alph0.3}{}}
\newlabel{equa_upper_bound_I2}{{4}{8}{Proof of theorems}{equation.Alph0.4}{}}
\newlabel{equa_cosine}{{5}{8}{Proof of theorems}{equation.Alph0.5}{}}
\newlabel{equa_A_upper_bound}{{6}{9}{Proof of theorems}{equation.Alph0.6}{}}
\newlabel{equa_recursive_upper_bound}{{7}{9}{Proof of theorems}{equation.Alph0.7}{}}
\newlabel{equa_strongly_convex}{{8}{10}{Proof of theorems}{equation.Alph0.8}{}}
\citation{Boyd:2004}
\newlabel{lemma_equivalent_update_proximal}{{3}{11}{}{Lemma.3}{}}
\newlabel{equa_lemma_equivalent_update_proximal_objective}{{9}{11}{Proof of lemmas}{equation.Alph0.9}{}}
\newlabel{equa_lemma_equivalent_update_proximal}{{10}{11}{Proof of lemmas}{equation.Alph0.10}{}}
\newlabel{lemma_I1_before}{{4}{11}{}{Lemma.4}{}}
\newlabel{equa_lemma_I1_before}{{11}{11}{}{equation.Alph0.11}{}}
\newlabel{equa_tau}{{12}{11}{Proof of lemmas}{equation.Alph0.12}{}}
\citation{Mokhtari:2016jz}
\bibdata{reference}
\newlabel{lemma_f_upper_bound}{{5}{12}{}{Lemma.5}{}}
\newlabel{equa_f_upper_bound}{{13}{12}{}{equation.Alph0.13}{}}
\newlabel{lemma_strongly_convex_regret}{{6}{12}{Appeared in Theorem $1$ in \cite {Mokhtari:2016jz}}{Lemma.6}{}}
